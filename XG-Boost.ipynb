{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG-Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omkarmutreja/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing all the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "[[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n",
      " [608 'Spain' 'Female' 41 1 83807.86 1 0 1 112542.58]\n",
      " [502 'France' 'Female' 42 8 159660.8 3 1 0 113931.57]\n",
      " [699 'France' 'Female' 39 1 0.0 2 0 0 93826.63]\n",
      " [850 'Spain' 'Female' 43 2 125510.82 1 1 1 79084.1]]\n",
      "[1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv(\"/Users/omkarmutreja/Downloads/XGBoost/Churn_Modelling.csv\")\n",
    "print(df.head())\n",
    "# Creating feature and target array\n",
    "X = df.iloc[:,3:13].values\n",
    "y = df.iloc[:,13].values\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical data\n",
    "labelEncoder_X1 = LabelEncoder()\n",
    "X[:,1] = labelEncoder_X1.fit_transform(X[:,1])\n",
    "labelEncoder_X2 = LabelEncoder()\n",
    "X[:,2] = labelEncoder_X2.fit_transform(X[:,2])\n",
    "oneHotEncoder = OneHotEncoder(categorical_features=[1])\n",
    "X =oneHotEncoder.fit_transform(X).toarray()\n",
    "X=X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1555   38]\n",
      " [ 229  178]]\n",
      "[0.87875 0.86    0.87125 0.85375 0.865   0.86375 0.87875 0.845   0.86625\n",
      " 0.86   ]\n",
      "Mean accuracy:  0.86425\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training and testing \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Fitting the XG-Boost model to the training set\n",
    "xgBoost = XGBClassifier()\n",
    "xgBoost.fit(X_train,y_train)\n",
    "y_pred = xgBoost.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "# Applying K-fold cross validation\n",
    "accuracy = cross_val_score(estimator=xgBoost,X=X_train,y=y_train,cv=10)\n",
    "print(accuracy)\n",
    "print(\"Mean accuracy: \",accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree : 0.7935000000000001\n",
      "RandomForest : 0.851375\n",
      "KNeighbours : 0.759625\n",
      "Support Vector Machine : 0.7962499999999999\n",
      "Naive Bayes  : 0.7856250000000001\n",
      "LogisticReg : 0.790625\n"
     ]
    }
   ],
   "source": [
    "# Comparing XG-Boost with other classification models\n",
    "classifiers = [['DecisionTree :',DecisionTreeClassifier()],\n",
    "               ['RandomForest :',RandomForestClassifier()],\n",
    "               ['KNeighbours :', KNeighborsClassifier()],\n",
    "               ['Support Vector Machine :',SVC()],\n",
    "               ['Naive Bayes  :',GaussianNB()],\n",
    "               ['LogisticReg :', LogisticRegression()]]\n",
    "\n",
    "for name,classifier in classifiers:\n",
    "    classifier = classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print(name, (cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864875\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# We can clearly see that XG-Boost performs the best as compared to other models.\n",
    "# We can also increase the model accuracy of all these models by tuning the parameters and performing GridSearch Cross Validation\n",
    "\n",
    "# Grid Search to find the best model and best parameters\n",
    "parameters = [{'max_depth':[2,3,4,5,6],'learning_rate':[0.5,0.1,0.01],\n",
    "               'n_estimators':[10,100,200]}]\n",
    "grid_search = GridSearchCV(estimator=xgBoost,param_grid=parameters,scoring='accuracy',cv=10,n_jobs=-1)\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that after tuning the parameters of the Xg-Bosst model, the accuracy increases from 86.33 to 86.55"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
